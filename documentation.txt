# S3 File Processing and PII Obfuscation Module

This Python module facilitates reading files from Amazon S3, obfuscating Personally Identifiable Information (PII), and writing processed data as byte streams. It supports CSV, JSON (line-delimited), and Parquet formats.

## Installation

```bash
pip install boto3 pandas pyarrow
```

## Functions

### `read_file_from_s3(bucket_name: str, object_key: str, file_format: str) -> pd.DataFrame`

Reads a file from S3 and returns a DataFrame.

#### Parameters:
- `bucket_name` (str): S3 bucket name.
- `object_key` (str): S3 object key.
- `file_format` (str): File format (`"csv"`, `"json"`, or `"parquet"`).

#### Returns:
- `pd.DataFrame`: Data from S3. Returns an empty DataFrame if the file is empty or cannot be parsed.

#### Raises:
- `ValueError`: Unsupported file format.
- `RuntimeError`: S3 read error.

#### Example:
```python
from your_module import read_file_from_s3

df = read_file_from_s3("my-bucket", "data.csv", "csv")
print(df.head())
```

### `obfuscate_pii(dataframe: pd.DataFrame, pii_fields: list) -> pd.DataFrame`

Replaces specified PII fields in a DataFrame with `"***"`.

#### Parameters:
- `dataframe` (pd.DataFrame): Input DataFrame.
- `pii_fields` (list): Column names containing PII.

#### Returns:
- `pd.DataFrame`: New DataFrame with obfuscated PII.

#### Example:
```python
from your_module import obfuscate_pii

obfuscated_df = obfuscate_pii(df, ["name", "email"])
print(obfuscated_df.head())
```

### `write_to_bytes(dataframe: pd.DataFrame, file_format: str) -> io.BytesIO`

Converts a DataFrame into a byte stream.

#### Parameters:
- `dataframe` (pd.DataFrame): Input DataFrame.
- `file_format` (str): Output format (`"csv"`, `"json"`, or `"parquet"`).

#### Returns:
- `io.BytesIO`: Byte stream of the formatted data.

#### Raises:
- `ValueError`: Unsupported file format.
- `RuntimeError`: Error writing to stream.

#### Example:
```python
from your_module import write_to_bytes

csv_buffer = write_to_bytes(obfuscated_df, "csv")
```

### `process_s3_file(json_input: str) -> io.BytesIO`

Reads an S3 file, obfuscates PII, and returns the processed data as a byte stream.

#### Parameters:
- `json_input` (str): JSON string specifying the S3 file and PII fields.

#### JSON Structure:
```json
{
  "file_to_obfuscate": "s3://my-bucket/data.csv",
  "pii_fields": ["name", "email"]
}
```

#### Returns:
- `io.BytesIO`: Processed data in CSV, JSON, or Parquet format.

#### Raises:
- `ValueError`: Invalid JSON input or unsupported file format.
- `RuntimeError`: S3 or processing error.

#### Example:
```python
from your_module import process_s3_file

json_input = '{"file_to_obfuscate": "s3://my-bucket/data.csv", "pii_fields": ["name", "email"]}'
processed_data = process_s3_file(json_input)

with open("obfuscated_data.csv", "wb") as f:
    f.write(processed_data.getvalue())
```

## Error Handling

- `ValueError` is raised for invalid input (e.g., unsupported file formats).
- `RuntimeError` is raised for S3 interaction or file processing errors.
- `read_file_from_s3` returns an empty DataFrame if the file is empty or unparseable to avoid pipeline failures.

## Dependencies

- `boto3`: AWS S3 interaction.
- `pandas`: Data manipulation.
- `pyarrow`: Parquet file handling.
- `io`: In-memory byte streams.
- `json`: JSON parsing.

## AWS Credentials

- When running on AWS (EC2, Lambda, etc.), IAM roles are used automatically.
- For local development, configure credentials via `~/.aws/credentials` or environment variables.
- **Never** hardcode AWS credentials.

## End-to-End Usage

1. Prepare a JSON input with the S3 URI and PII fields.
2. Call `process_s3_file` with the JSON string.
3. Use the returned `io.BytesIO` object to save or upload the processed data.

Replace `your_module` with the actual module name in your implementation.

